# [LCC系列] 激光雷达和相机联合标定 之 开源代码和软件汇总 （2004-2021） - 知乎
## 前言

> LiDAR Camera Calibration (LCC) 系列，主要介绍激光雷达相机外参标定相关内容。本文主要介绍相关的开源代码和软件，主要包括 target-based 和 targetless 两类方法，每个方法对应标题后说明了方法的提出年份和开源代码的语言（c : c++, p: python, m: matlab）。

Github 同步更新：

## 1. target-based 方法

一般就是使用标定板，可以是一块普通的矩形板，可以添加视觉效果（比如棋盘格，ArUco)，可以在矩形板上镂空出特定形状。

### 1.0 CamLaserCalibraTool (2004c)

![](https://pic3.zhimg.com/v2-fd1de6e0c6120fbda9fe043ff2e1d0aa_b.jpg)

主要参考了华盛顿大学 2004 年的论文，旷视提供了开源实现和博客解读。 2D 激光雷达和相机标定。主要利用点到平面和边缘的约束。详情见**旷视**的博客和开源：

-   **github**：[MegviiRobot/CamLaserCalibraTool](https://link.zhihu.com/?target=https%3A//github.com/MegviiRobot/CamLaserCalibraTool)
-   **博客**：[标定系列三 | 实践之 Camera-Lidar 标定](https://zhuanlan.zhihu.com/p/137501892)
-   **参考论文：**  [Extrinsic Calibration of a Camera and Laser Range Finder (improves camera calibration)](https://link.zhihu.com/?target=http%3A//citeseerx.ist.psu.edu/viewdoc/download%3Fdoi%3D10.1.1.80.7118%26rep%3Drep1%26type%3Dpdf)

### 1.1 LCCT (2005m)

来自 CMU Robotics Institute, 已知最早 3D Laser 与相机标定的工作（2005 年），基于**matlab**的图形用户界面，进行激光雷达相机外参标定。

**target-based**方法，使用标定板，采集多个点云图像对，在点云对应的深度图 (range image) 上**框选标定板平面区域**，即可求解外参（两阶段）。

第一阶段，分别最小化**两个坐标系中相机中心到平面距离和平面法向量的差异**，依次线性求解平移和旋转；第二阶段，最小化**point-to-plane**距离，迭代求解。

![](https://pic1.zhimg.com/v2-25784f56ccc5abd2e7ee1e143a9a1e00_b.jpg)

-   **官方网站**：[The Laser-Camera Calibration Toolbox](https://link.zhihu.com/?target=http%3A//www.cs.cmu.edu/~ranjith/lcct.html)
-   **参考论文**：2005_Fast Extrinsic Calibration of a Laser Rangefinder to a Camera

### 1.2 cam_lidar_calib (2010c)

来自密歇根大学，ROS / C++ 实现。

![](https://pic4.zhimg.com/v2-8ea16291acb1fd7123a99d424093c0ab_b.jpg)

使用 checkerboard, 最少需要 3 个视图。自动提取特征，图像中提取 checkerboard 在相机坐标系中的法向量和距相机原点的距离，点云中提取 checkerboard 的平面点。

-   **Github 开源：**  [https://github.com/SubMishMar/cam_lidar_calib](https://link.zhihu.com/?target=https%3A//github.com/SubMishMar/cam_lidar_calib)
-   **参考论文:** [Extrinsic calibration of a 3d laser scanner and an omnidirectional camera](https://link.zhihu.com/?target=http%3A//robots.engin.umich.edu/publications/gpandey-2010a.pdf)

### 1.3 lidar_camera_calibration (2017c)

来自印度 IIIT Robotics Research Lab，ROS package (C++) 实现, 介绍了两种方法。 第一种方法是基于**2D-3D correspondence**，采用**中空矩形纸板**作为目标，在**图像上手动标记角点 2D 像素，在点云中手动框选线段**，利用直线相交求解 3D 角点，然后利用 PnP+ransac 求解外参。缺点是手动标记像素点，误差较大。

![](https://pic2.zhimg.com/v2-a270dbc3c477d56925f260b98301bc75_b.jpg)

第二种方法是基于**3D-3D correspondence**，与方法一主要区别是图像中特征的提取。通过采用**ArUco**二维码，可直接计算出角点在相机坐标系的 3D 坐标，然后利用**ICP**求解外参。

![](https://pic1.zhimg.com/v2-9a2615206a60099c917bd02118e8be14_b.jpg)

-   **github 开源**：[https://github.com/ankitdhall/lidar_camera_calibration](https://link.zhihu.com/?target=https%3A//github.com/ankitdhall/lidar_camera_calibration)
-   **参考论文**：[LiDAR-Camera Calibration using 3D-3D Point correspondences (2017)](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1705.09785v1.pdf)

### 1.4 ILCC (2017p)

来自日本名古屋大学 Nagoya University，python 实现。完整流程如下：

![](https://pic2.zhimg.com/v2-eb5d994ea16d66a8d71f04cda23a0b61_b.jpg)

该方法的 3D 角点提取方式比较独特。基于点云反射强度和 chessboard 颜色模式的相关性，**利用一个 chessboard model 来拟合（匹配）分割的点云**，从而利用 chessboard model 的角点位置表示 chessboard 点云中角点位置。

![](https://pic4.zhimg.com/v2-6ded5d4899b92b0d8ee8d28375c3b177_b.jpg)

-   **github 开源**：[https://github.com/mfxox/ILCC](https://link.zhihu.com/?target=https%3A//github.com/mfxox/ILCC)
-   **参考论文**：[2017_Remot Sensing_Reflectance Intensity Assisted Automatic and Accurate Extrinsic Calibration of 3D LiDAR and Panoramic Camera Using a Printed Chessboard](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1708.05514.pdf)

### 1.5 plycal (2018c)

来自 HKUST，C++ 实现。

采用要给**矩形板**作为 target。首先对激光雷达和相机时间同步，图像纠正。全自动地在图像中提取矩形板角点和边缘，在点云中提取矩形板的边缘和平面点。矩形特征 2D-3D 匹配。采用**point-to-line**和**point-inside-polygon**约束进行优化。

![](https://pic3.zhimg.com/v2-77bee583600dfb4978c81718d5570316_b.jpg)

-   **github 开源**： [https://github.com/ram-lab/plycal](https://link.zhihu.com/?target=https%3A//github.com/ram-lab/plycal)
-   **参考论文**：2018_ROBIO_Extrinsic Calibration of Lidar and Camera with Polygon

### 1.6 Matlab Lidar Toolbox (2018m)

**target-based**方法，使用了 chessboard, 理论上采集一个 pose 就可以求解。 特征提取分别**自动提取 chessboard 在相机和激光雷达坐标系的平面和边缘信息**，利用 line correspondence (direction constraint + point to line constraint) 和**plane correspondence (normal constraint + point to plane constraint)**进行标定。

![](https://pic2.zhimg.com/v2-42d7b4d32a4449d61bc51858c642bfa1_b.jpg)

-   **官方文档**：[Lidar and Camera Calibration](https://link.zhihu.com/?target=https%3A//ww2.mathworks.cn/help/lidar/ug/lidar-and-camera-calibration.html)  
-   **参考论文**：[Lipu Zhou and Zimo Li and Michael Kaess, "Automatic Extrinsic Calibration of a Camera and a 3D LiDAR using Line and Plane Correspondences", "IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems, IROS", Oct, 2018.](https://link.zhihu.com/?target=http%3A//www.cs.cmu.edu/~kaess/pub/Zhou18iros.pdf)  
-   **csdn 博客**：[MATLAB 终于可以完成相机与激光雷达的标定啦！！(包含 matlab2020 下载链接)](https://link.zhihu.com/?target=https%3A//blog.csdn.net/qq_27339501/article/details/110224436)

> 只能使用 matlab 的 lidar toolbox, 看不到源代码  
> 该方法与 plycal(2018c) 的标定板点云特征提取方法类似。

### 1.7 extrinsic_lidar_camera_calibration （2020m）

来自 Robotics Institute, University of Michigan。matlab 实现。

主要创新点是标定板点云的角点估计方法。假设在 lidar 原点有一个大小已知的参考标定板（reference target），希望标定板点云通过 H 变换后，与这个参考标定板尽量重合。优化求解 H，将参考标定板角点反变换，即可得到点云中的角点位置。

> 之前方法采用先拟合边缘再直线相交的思路，只利用了边缘点，受点云深度测量误差影响，最后提取的四个角点可能与 target 真实几何不兼容。该方法的角点估计考虑了所有点，估计的四个角点也是与真实 target 形状兼容。  
> 该方法与 ILCC(2017p) 方法类似，都是通过与一个参考的标定板拟合，从而对标定板点云参数化建模，求得角点。只是 ILCC 利用了点云反射强度，本方法只利用点云几何信息。

![](https://pic1.zhimg.com/v2-b8c7b08862f6bc020855cf204b189124_b.jpg)

**github 开源**：[https://github.com/UMich-BipedLab/extrinsic_lidar_camera_calibration](https://link.zhihu.com/?target=https%3A//github.com/UMich-BipedLab/extrinsic_lidar_camera_calibration)

> 该开源代码也实现了 Matlab Lidar Toolbox (2018m) 参考论文中点云边缘提取的方法：1）先 ransac 拟合平面，2), 找到每条 scanline 的端点（边缘点），3）将标定板点云投影到拟合平面，4）拟合每条 scan line, 5) 将边缘点投影到拟合的 scan line, 6) 用 ransac 拟合边缘，去除边缘点粗差  
> **参考论文**：2020_IEEE access_Improvements to Target-Based 3D LiDAR to Camera Calibration  

### 1.8 livox_camera_lidar_calibration（2020c）

Livox 官方提供的 Lidar-Camera 标定代码，图像和点云都是手动标点。 **github 开源**: [https://github.com/Livox-SDK/livox_camera_lidar_calibration](https://link.zhihu.com/?target=https%3A//github.com/Livox-SDK/livox_camera_lidar_calibration)

### 1.9 ACSC (2020p)

来自北航，python 实现，针对固态激光雷达 Livox.

提出多帧点云集成精化算法 (temporal-spatial-based geometric feature refinement) 和基于反射强度分布的角点估计方法(reflectance intensity distribution-based 3D corner estimation )。自动提取 2D 和 3D 角点，然后用基于 Ransac 的 PnP 求解。

![](https://pic3.zhimg.com/v2-63b3ca02d642d8426283dada5df72daa_b.jpg)

-   **github 开源**:[https://github.com/HViktorTsoi/ACSC](https://link.zhihu.com/?target=https%3A//github.com/HViktorTsoi/ACSC)
-   **参考论文**：ACSC: Automatic Calibration for Non-repetitive Scanning Solid-State LiDAR and Camera Systems

### 1.10 velo2cam_calibration （2021c）

来自 Intelligent Systems Lab (LSI), Universidad Carlos III de Madrid, Leganes, ROS + C++ 实现。可以将激光雷达、单目相机、立体相机进行任意成对标定。需要比较特殊的标定板：

![](https://pic2.zhimg.com/v2-4bf3e84e8edaaa36a834001659a2aa15_b.jpg)

-   **github 开源**：[https://github.com/beltransen/velo2cam_calibration](https://link.zhihu.com/?target=https%3A//github.com/beltransen/velo2cam_calibration)
-   **参考论文**： Beltrán, J., Guindel, C., and García, F. (2021). Automatic Extrinsic Calibration Method for LiDAR and Camera Sensor Setups. arXiv:2101.04431 \[cs.RO]. Submitted to IEEE Transactions on Intelligent Transportation Systems.

### 1.11 autoware

-   采用标定板的方法 (calibration_tookit， autoware1.10 之后没有)

-   **github**: [calibration_camera_lidar](https://link.zhihu.com/?target=https%3A//github.com/XidianLemon/calibration_camera_lidar)

-   **博客**: [无人驾驶汽车系统入门（二十二）——使用 Autoware 实践激光雷达与摄像机组合标定](https://link.zhihu.com/?target=https%3A//adamshan.blog.csdn.net/article/details/81670732) [Autoware calibration toolkit 激光雷达与相机外参联合标定](https://link.zhihu.com/?target=https%3A//www.cnblogs.com/xiangzh/p/14137345.html)  


-   直接手动选点的方法 ： [使用 autoware1.1 进行相机标定和联合标定](https://link.zhihu.com/?target=https%3A//dlonng.com/posts/autoware-calibr-1)  

> 最新版只有 autoware_camera_lidar_calibrator， 直接手动选点的方法，在下文介绍。
>
> 使用标定板结果更准确一些，但是操作不方便。1）需要手动 grab 多个关键帧，2) 使用 glviewer 显示点云，不好调整视角，3）需要手动选择平面点云

### 1.12 LIBCBDETECT （2012 m）

棋盘格角点的亚像素级检测，matlab 实现。可用于针孔相机，鱼眼相机，全景相机。来自论文：

![](https://pic3.zhimg.com/v2-eef0dc3c27b564fe2f8b3e569e2466f6_b.jpg)

### 1.13 multiple-cameras-and-3D-LiDARs-extrinsic-calibration

-   论文：Single-Shot is Enough: Panoramic Infrastructure Based Calibration of Multiple Cameras and 3D LiDARs
-   代码：[multiple-cameras-and-3D-LiDARs-extrinsic-calibration](https://link.zhihu.com/?target=https%3A//github.com/alibaba/multiple-cameras-and-3D-LiDARs-extrinsic-calibration)

![](https://pic1.zhimg.com/v2-d4a2a44d6b00ba3d90eaf9d93838e028_b.jpg)

## 2 targetless 方法

### 2.1 apollo

是基于自然场景的**targetless**方法，不需要手动标记，但是需要**较准确初值**。

![](https://pic4.zhimg.com/v2-faddad50e81712a79854e59e6a6ea93b_b.jpg)

（一个比较好的标定场景，包含路灯，树木，道路等物体）

> 注意：核心代码没有开源  

-   **github 文档**: [Apollo 2.0 Sensor Calibration Guide](https://link.zhihu.com/?target=https%3A//github.com/ApolloAuto/apollo/blob/master/docs/quickstart/apollo_2_0_sensor_calibration_guide.md)
-   **csdn 博客**: [激光雷达和相机的联合标定（Camera-LiDAR Calibration）之 apollo](https://link.zhihu.com/?target=https%3A//blog.csdn.net/learning_tortosie/article/details/82351553%3Futm_medium%3Ddistribute.pc_relevant.none-task-blog-baidujs_baidulandingword-0%26spm%3D1001.2101.3001.4242)

### 2.2 autoware

没有 target, 但是需要手动标记图像和点云中的对应点，至少选择 9 对。

-   **github 文档**：[Autoware Camera-LiDAR Calibration Package](https://link.zhihu.com/?target=https%3A//github.com/Autoware-AI/utilities/tree/master/autoware_camera_lidar_calibrator)  
-   **csdn 博客**：[激光雷达和相机的联合标定（Camera-LiDAR Calibration）之 Autoware](https://link.zhihu.com/?target=https%3A//blog.csdn.net/learning_tortosie/article/details/82347694)  

### 2.3 ExtrinsicCalib （2012c）

先将图像进行灰度化和直方图均衡化，得到灰度图像，然后根据点云的反射强度和法向量特征将点云投影为图像，使用标准化互信息衡量灰度图像和点云生成图像之间相关性。使用粒子群优化算法不断改变外参，直到粒子收敛，达到标准化互信息的最大值。

**论文**：2012_Automatic Targetless Extrinsic Calibration of a 3D Lidar and Camera by Maximizing Mutual Information

-   [官网：（包含代码，数据）](https://link.zhihu.com/?target=http%3A//robots.engin.umich.edu/SoftwareData/ExtrinsicCalib)

局限性：对于图像，光照会影响像素亮度，且存在阴影问题；点云强度则不同，由于激光是主动式。因此，利用多视图数据，可以尽量避免光照、阴影造成的噪声，使误差函数相对平滑，便于优化。

### 2.3 CamVox (2020c)

来自南方科技大学。图像先灰度化再提取边缘，点云先分别得到反射强度图和深度图，再提取边缘。通过 ICP 优化，求解最佳外参。

![](https://pic3.zhimg.com/v2-4943fd80a849d07f446d4648ce1a6a5a_b.jpg)

-   **github:** [https://github.com/xuankuzcr/CamVox](https://link.zhihu.com/?target=https%3A//github.com/xuankuzcr/CamVox)
-   **论文：**  VCamVox: A Low-cost and Accurate Lidar-assisted Visual SLAM System

### 2.4 livox camera calib （2020c）

来自香港大学。分别提取点云和图像中的边缘特征，然后匹配特征，最后优化求解最佳外参来更好地对齐点云边缘和图像边缘。

![](https://pic3.zhimg.com/v2-d745d47e478470adb9d8da64bf33663a_b.jpg)

-   **论文：** [Pixel-level Extrinsic Self Calibration of High Resolution LiDAR and Camera in Targetless Environments](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2103.01627v2.pdf)
-   **作者：** Chongjian Yuan (香港大学)
-   **Github:** [hku-mars/livox camera calib](https://link.zhihu.com/?target=https%3A//github.com/hku-mars/livox_camera_calib)

论文详细解读请参考：

-   **博客：**  [【LCC 系列】不用标定目标，实现高分辨率激光雷达和相机的像素级自标定](https://link.zhihu.com/?target=https%3A//blog.csdn.net/muyiyushan/article/details/118573929)

场景选择： 避免圆柱物体，避免纹理过多（树木，花草等），边缘均匀分布，多个方向的边缘 [Issue with finding depth-continuous regions （github）](https://link.zhihu.com/?target=https%3A//github.com/hku-mars/livox_camera_calib/issues/4)

### 2.5 mlcc

-   论文：Fast and Accurate Extrinsic Calibration for Multiple LiDARs and Cameras
-   代码：[https://github.com/hku-mars/mlcc](https://link.zhihu.com/?target=https%3A//github.com/hku-mars/mlcc)

![](https://pic2.zhimg.com/v2-d7a7885b64b4783e20b0e829acc19c01_b.jpg) 
 [https://zhuanlan.zhihu.com/p/404762012](https://zhuanlan.zhihu.com/p/404762012)
