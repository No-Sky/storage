# 激光雷达和相机联合标定之开源代码和软件汇总（2004-2021）_3Ｄ视觉工坊的博客-CSDN博客
作者丨十点雨 @知乎

来源丨[https://zhuanlan.zhihu.com/p/404762012](https://zhuanlan.zhihu.com/p/404762012)

编辑丨 3D 视觉工坊

> LiDAR Camera Calibration (LCC) 系列，主要介绍激光雷达相机外参[标定](https://so.csdn.net/so/search?q=%E6%A0%87%E5%AE%9A&spm=1001.2101.3001.7020)相关内容。本文主要介绍相关的开源代码和软件，主要包括 target-based 和 targetless 两类方法，每个方法对应标题后说明了方法的提出年份和开源代码的语言（c : c++, p: python, m: matlab）。

## Github 同步更新：[https://github.com/Deephome/Awesome-LiDAR-Camera-Calibration](https://github.com/Deephome/Awesome-LiDAR-Camera-Calibration)

## **1. target-based 方法**

一般就是使用标定板，可以是一块普通的矩形板，可以添加视觉效果（比如棋盘格，ArUco)，可以在矩形板上镂空出特定形状。

1.0 CamLaserCalibraTool (2004c)

![](https://img-blog.csdnimg.cn/img_convert/5d97b9dd398024716cce770369bfc3f1.png)

主要参考了华盛顿大学 2004 年的论文，旷视提供了开源实现和博客解读。2D 激光雷达和相机标定。主要利用点到平面和边缘的约束。详情见旷视的博客和开源：  

1）github：[https://github.com/MegviiRobot/CamLaserCalibraTool](https://github.com/MegviiRobot/CamLaserCalibraTool)

2）博客：标定系列三 | 实践之 Camera-Lidar 标定（[https://zhuanlan.zhihu.com/p/137501892）](https://zhuanlan.zhihu.com/p/137501892）)

3）参考论文：Extrinsic Calibration of a Camera and Laser Range Finder (improves camera calibration)（[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.80.7118&rep=rep1&type=pdf）](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.80.7118&rep=rep1&type=pdf）)

1.1 LCCT (2005m)

来自 CMU Robotics Institute, 已知最早 3D Laser 与相机标定的工作（2005 年），基于 matlab 的图形用户界面，进行激光雷达相机外参标定。

target-based 方法，使用标定板，采集多个点云图像对，在点云对应的深度图 (range image) 上框选标定板平面区域，即可求解外参（两阶段）。

第一阶段，分别最小化两个坐标系中相机中心到平面距离和平面法向量的差异，依次线性求解平移和旋转；第二阶段，最小化 point-to-plane 距离，迭代求解。

![](https://img-blog.csdnimg.cn/img_convert/1fa3fb9a3b213777ff6c7b3ca8b9ebee.png)

官方网站：[http://www.cs.cmu.edu/~ranjith/lcct.html](http://www.cs.cmu.edu/~ranjith/lcct.html)

参考论文：2005_Fast Extrinsic Calibration of a Laser Rangefinder to a Camera

1.2 cam_lidar_calib (2010c)

来自密歇根大学，ROS / C++ 实现。

![](https://img-blog.csdnimg.cn/img_convert/a235904b2062c0d053cb73bf5bd5cb03.png)

使用 checkerboard, 最少需要 3 个视图。自动提取特征，图像中提取 checkerboard 在相机坐标系中的法向量和距相机原点的距离，点云中提取 checkerboard 的平面点。

Github 开源：[https://link.zhihu.com/?target=https%3A//github.com/SubMishMar/cam\\\_lidar\\\_calib](https://link.zhihu.com/?target=https%3A//github.com/SubMishMar/cam\_lidar\_calib)

参考论文: [http://robots.engin.umich.edu/publications/gpandey-2010a.pdf](http://robots.engin.umich.edu/publications/gpandey-2010a.pdf)

1.3 lidar_camera_calibration (2017c)

来自印度 IIIT Robotics Research Lab，ROS package (C++) 实现, 介绍了两种方法。第一种方法是基于 2D-3D correspondence，采用中空矩形纸板作为目标，在图像上手动标记角点 2D 像素，在点云中手动框选线段，利用直线相交求解 3D 角点，然后利用 PnP+ransac 求解外参。缺点是手动标记像素点，误差较大。

![](https://img-blog.csdnimg.cn/img_convert/7d92b0ecc42f7b3961900bb191e65dee.png)

第二种方法是基于 3D-3D correspondence，与方法一主要区别是图像中特征的提取。通过采用 ArUco 二维码，可直接计算出角点在相机坐标系的 3D 坐标，然后利用 ICP 求解外参。

![](https://img-blog.csdnimg.cn/img_convert/af3ff374a29b64be938d108d32ed7808.png)

github 开源：github.com/ankitdhall/l

参考论文：LiDAR-Camera Calibration using 3D-3D Point correspondences (2017)（[https://arxiv.org/pdf/1705.09785v1.pdf）](https://arxiv.org/pdf/1705.09785v1.pdf）)

1.4 ILCC (2017p)

来自日本名古屋大学 Nagoya University，python 实现。完整流程如下：

![](https://img-blog.csdnimg.cn/img_convert/6e2f82e4507717ac3129095682bb0462.png)

该方法的 3D 角点提取方式比较独特。基于点云反射强度和 chessboard 颜色模式的相关性，利用一个 chessboard model 来拟合（匹配）分割的点云，从而利用 chessboard model 的角点位置表示 chessboard 点云中角点位置。  

![](https://img-blog.csdnimg.cn/img_convert/c2a6428419f5ef91bc6683bd076492b5.png)

github 开源：[https://github.com/mfxox/ILCC](https://github.com/mfxox/ILCC)

参考论文：2017_Remot Sensing_Reflectance Intensity Assisted Automatic and Accurate Extrinsic Calibration of 3D LiDAR and Panoramic Camera Using a Printed Chessboard（[https://arxiv.org/pdf/1708.05514.pdf）](https://arxiv.org/pdf/1708.05514.pdf）)

1.5 plycal (2018c)

来自 HKUST，C++ 实现。

采用要给矩形板作为 target。首先对激光雷达和相机时间同步，图像纠正。全自动地在图像中提取矩形板角点和边缘，在点云中提取矩形板的边缘和平面点。矩形特征 2D-3D 匹配。采用 point-to-line 和 point-inside-polygon 约束进行优化。

![](https://img-blog.csdnimg.cn/img_convert/222d721c76d321d1246ee76844dabf7f.png)

github 开源：[https://github.com/ram-lab/plycal](https://github.com/ram-lab/plycal)

参考论文：2018_ROBIO_Extrinsic Calibration of Lidar and Camera with Polygon

1.6 Matlab Lidar Toolbox (2018m)

target-based 方法，使用了 chessboard, 理论上采集一个 pose 就可以求解。特征提取分别自动提取 chessboard 在相机和激光雷达坐标系的平面和边缘信息，利用 line correspondence (direction constraint + point to line constraint) 和 plane correspondence (normal constraint + point to plane constraint) 进行标定。

![](https://img-blog.csdnimg.cn/img_convert/cb0950896e2b0e6fcb9c3f12efe3ea94.png)

官方文档：[https://ww2.mathworks.cn/help/lidar/ug/lidar-and-camera-calibration.html](https://ww2.mathworks.cn/help/lidar/ug/lidar-and-camera-calibration.html)  

参考论文：Lipu Zhou and Zimo Li and Michael Kaess, "Automatic Extrinsic Calibration of a Camera and a 3D LiDAR using Line and Plane Correspondences", "IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems, IROS", Oct, 2018.  

csdn 博客：MATLAB 终于可以完成相机与激光雷达的标定啦！！(包含 matlab2020 下载链接)

> 只能使用 matlab 的 lidar toolbox, 看不到源代码  
> 该方法与 plycal(2018c) 的标定板点云特征提取方法类似。

1.7 extrinsic_lidar_camera_calibration （2020m）  

来自 Robotics Institute, University of Michigan。matlab 实现。

主要创新点是标定板点云的角点估计方法。假设在 lidar 原点有一个大小已知的参考标定板（reference target），希望标定板点云通过 H 变换后，与这个参考标定板尽量重合。优化求解 H，将参考标定板角点反变换，即可得到点云中的角点位置。

> 之前方法采用先拟合边缘再直线相交的思路，只利用了边缘点，受点云深度测量误差影响，最后提取的四个角点可能与 target 真实几何不兼容。该方法的角点估计考虑了所有点，估计的四个角点也是与真实 target 形状兼容。  
> 该方法与 ILCC(2017p) 方法类似，都是通过与一个参考的标定板拟合，从而对标定板点云参数化建模，求得角点。只是 ILCC 利用了点云反射强度，本方法只利用点云几何信息。

![](https://img-blog.csdnimg.cn/img_convert/7a019d135a6f352d3d5f4be5087a2510.png)

github 开源：[https://github.com/UMich-BipedLab/extrinsic\\\_lidar\\\_camera\\\_calibration](https://github.com/UMich-BipedLab/extrinsic\_lidar\_camera\_calibration)

> 该开源代码也实现了 Matlab Lidar Toolbox (2018m) 参考论文中点云边缘提取的方法：1）先 ransac 拟合平面，2), 找到每条 scanline 的端点（边缘点），3）将标定板点云投影到拟合平面，4）拟合每条 scan line, 5) 将边缘点投影到拟合的 scan line, 6) 用 ransac 拟合边缘，去除边缘点粗差  
> 参考论文：2020_IEEE access_Improvements to Target-Based 3D LiDAR to Camera Calibration

1.8 livox_camera_lidar_calibration（2020c）  

* * *

Livox 官方提供的 Lidar-Camera 标定代码，图像和点云都是手动标点。 github 开源: [https://github.com/Livox-SDK/livox\\\_camera\\\_lidar\\\_calibration](https://github.com/Livox-SDK/livox\_camera\_lidar\_calibration)

## 1.9 ACSC (2020p)

来自北航，python 实现，针对固态激光雷达 Livox.

提出多帧点云集成精化算法 (temporal-spatial-based geometric feature refinement) 和基于反射强度分布的角点估计方法(reflectance intensity distribution-based 3D corner estimation )。自动提取 2D 和 3D 角点，然后用基于 Ransac 的 PnP 求解。

![](https://img-blog.csdnimg.cn/img_convert/b82e640f9d8ead58255a2100f9608e69.png)

github 开源:[https://github.com/HViktorTsoi/ACSC](https://github.com/HViktorTsoi/ACSC)

参考论文：ACSC: Automatic Calibration for Non-repetitive Scanning Solid-State LiDAR and Camera Systems

1.10 velo2cam_calibration （2021c）

来自 Intelligent Systems Lab (LSI), Universidad Carlos III de Madrid, Leganes, ROS + C++ 实现。可以将激光雷达、单目相机、立体相机进行任意成对标定。需要比较特殊的标定板：

![](https://img-blog.csdnimg.cn/img_convert/c040f72622dac66f9ebd8d9fd23fbd8e.png)

github 开源：[https://github.com/beltransen/velo2cam\\\_calibration](https://github.com/beltransen/velo2cam\_calibration)

参考论文：Beltrán, J., Guindel, C., and García, F. (2021). Automatic Extrinsic Calibration Method for LiDAR and Camera Sensor Setups. arXiv:2101.04431 \[cs.RO]. Submitted to IEEE Transactions on Intelligent Transportation Systems.

1.11 autoware

采用标定板的方法 (calibration_tookit， autoware1.10 之后没有)

github: [https://github.com/XidianLemon/calibration\\\_camera\\\_lidar](https://github.com/XidianLemon/calibration\_camera\_lidar)

博客: 无人驾驶汽车系统入门（二十二）——使用 Autoware 实践激光雷达与摄像机组合标定、Autoware calibration toolkit 激光雷达与相机外参联合标定

直接手动选点的方法 ：[https://dlonng.com/posts/autoware-calibr-1](https://dlonng.com/posts/autoware-calibr-1)  

> 最新版只有 autoware_camera_lidar_calibrator， 直接手动选点的方法，在下文介绍。
>
> 使用标定板结果更准确一些，但是操作不方便。1）需要手动 grab 多个关键帧，2) 使用 glviewer 显示点云，不好调整视角，3）需要手动选择平面点云

## 2 targetless 方法

## 2.1 apollo

是基于自然场景的 targetless 方法，不需要手动标记，但是需要较准确初值。

![](https://img-blog.csdnimg.cn/img_convert/da0ffff4d24082d24fd417e2ec676d8f.png)

（一个比较好的标定场景，包含路灯，树木，道路等物体）

> 注意：核心代码没有开源

github 文档: [https://github.com/ApolloAuto/apollo/blob/master/docs/quickstart/apollo\\\_2\\\_0\\\_sensor\\\_calibration\\\_guide.md](https://github.com/ApolloAuto/apollo/blob/master/docs/quickstart/apollo\_2\_0\_sensor\_calibration\_guide.md)  

csdn 博客: 激光雷达和相机的联合标定（Camera-LiDAR Calibration）之 apollo

备注：感谢微信公众号「**3D 视觉工坊**」整理。  

2.2 autoware

没有 target, 但是需要手动标记图像和点云中的对应点，至少选择 9 对。

github 文档：[https://github.com/Autoware-AI/utilities/tree/master/autoware\\\_camera\\\_lidar\\\_calibrator](https://github.com/Autoware-AI/utilities/tree/master/autoware\_camera\_lidar\_calibrator)  

csdn 博客：激光雷达和相机的联合标定（Camera-LiDAR Calibration）之 Autoware  

## 2.3 ExtrinsicCalib （2012c）

先将图像进行灰度化和直方图均衡化，得到灰度图像，然后根据点云的反射强度和法向量特征将点云投影为图像，使用标准化互信息衡量灰度图像和点云生成图像之间相关性。使用粒子群优化算法不断改变外参，直到粒子收敛，达到标准化互信息的最大值。

论文：2012_Automatic Targetless Extrinsic Calibration of a 3D Lidar and Camera by Maximizing Mutual Information

官网：（包含代码，数据）[http://robots.engin.umich.edu/SoftwareData/ExtrinsicCalib](http://robots.engin.umich.edu/SoftwareData/ExtrinsicCalib)

局限性：对于图像，光照会影响像素亮度，且存在阴影问题；点云强度则不同，由于激光是主动式。因此，利用多视图数据，可以尽量避免光照、阴影造成的噪声，使误差函数相对平滑，便于优化。

## 2.3 CamVox (2020c)

来自南方科技大学。图像先灰度化再提取边缘，点云先分别得到反射强度图和深度图，再提取边缘。通过 ICP 优化，求解最佳外参。

![](https://img-blog.csdnimg.cn/img_convert/fc233645f02f679197909766a93c0cee.png)

github:[https://github.com/xuankuzcr/CamVox](https://github.com/xuankuzcr/CamVox)

论文： VCamVox: A Low-cost and Accurate Lidar-assisted Visual SLAM System

2.4 livox camera calib （2020c）

来自香港大学。分别提取点云和图像中的边缘特征，然后匹配特征，最后优化求解最佳外参来更好地对齐点云边缘和图像边缘。

![](https://img-blog.csdnimg.cn/img_convert/1168df6313ace9589b239d0cf710fb8c.png)

论文：Pixel-level Extrinsic Self Calibration of High Resolution LiDAR and Camera in Targetless Environments

作者：Chongjian Yuan (香港大学)

Github:[https://github.com/hku-mars/livox\\\_camera\\\_calib](https://github.com/hku-mars/livox\_camera\_calib)

论文详细解读请参考：

博客：【LCC 系列】不用标定目标，实现高分辨率激光雷达和相机的像素级自标定

场景选择：避免圆柱物体，避免纹理过多（树木，花草等），边缘均匀分布，多个方向的边缘 Issue with finding depth-continuous regions （github）（[https://github.com/hku-mars/livox\\\_camera\\\_calib/issues/4）](https://github.com/hku-mars/livox\_camera\_calib/issues/4）)

本文仅做学术分享，如有侵权，请联系删文。

**下载 1**

在「3D 视觉工坊」公众号后台回复：**3D 视觉 \*\***，\*\* 即可下载 3D 视觉相关资料干货，涉及相机标定、三维重建、立体视觉、SLAM、深度学习、点云后处理、多视图几何等方向。

**下载 2**

在「3D 视觉工坊」公众号后台回复：**3D 视觉 github 资源汇总 \*\***，**即可下载包括**结构光、标定源码、缺陷检测源码、深度估计与深度补全源码、点云处理相关源码、立体匹配源码、单目、双目 3D 检测、基于点云的 3D 检测、6D 姿态估计源码汇总 \*\* 等。

**下载 3**

在「3D 视觉工坊」公众号后台回复：**相机标定 \*\***，**即可下载独家**相机标定**学习课件与视频网址；后台回复：**立体匹配 \***\*，**即可下载独家**立体匹配**学习课件与视频网址。

**重磅！\*\***3DCVer-\***\* 学术论文写作投稿 \*\***交流群 \***\* 已成立**

扫码添加小助手微信，可**申请加入 3D 视觉工坊 - 学术论文写作与投稿 微信交流群，旨在交流顶会、顶刊、SCI、EI 等写作与投稿事宜。** 

**同时**也可申请加入我们的细分方向交流群，目前主要有**3D 视觉**、**CV & 深度学习**、**SLAM**、**三维重建**、**点云后处理**、**自动驾驶、多传感器融合、CV 入门、三维测量、VR/AR、3D 人脸识别、医疗影像、缺陷检测、行人重识别、目标跟踪、视觉产品落地、视觉竞赛、车牌识别、硬件选型、**学术交流、**求职交流、ORB-SLAM 系列源码交流、深度估计**等微信群。

一定要备注：**研究方向 + 学校 / 公司 + 昵称**，例如：”3D 视觉 + 上海交大 + 静静 “。请按照格式备注，可快速被通过且邀请进群。**原创投稿**也请联系。

![](https://img-blog.csdnimg.cn/img_convert/e3a76c487f0c1084b7440e02cede5e83.png)

▲长按加微信群或投稿

![](https://img-blog.csdnimg.cn/img_convert/4c26a6e50f2468b795d85de83a423e7d.png)

▲长按关注公众号

* * *

**3D 视觉从入门到精通知识星球**：针对 3D 视觉领域的**视频课 \*\***程（[三维重建系列](http://mp.weixin.qq.com/s?__biz=MzU1MjY4MTA1MQ%3D%3D&chksm=fbfc281ecc8ba10823e11ac0044b5a94920806c83d30d8cb90630a41ecb23ad458106b9b1f58&idx=1&mid=2247549738&scene=21&sn=88b4aa9e091077f107407bddc8da7acd#wechat_redirect)、[三维点云系列](http://mp.weixin.qq.com/s?__biz=MzU1MjY4MTA1MQ%3D%3D&chksm=fbfc21bdcc8ba8abac371478a6b2b9d143a1b31fa799201c6682d9d0b6a4ed4a7da146b3c536&idx=1&mid=2247551625&scene=21&sn=4a914cfeb2d251ab25421e1e5de930c0#wechat_redirect)、[结构光系列](http://mp.weixin.qq.com/s?__biz=MzU1MjY4MTA1MQ%3D%3D&chksm=fbfc1e98cc8b978e5fb6b2afd1a473c89e2861374542421b9972f87a6fdfcd47eb50c443042e&idx=2&mid=2247546284&scene=21&sn=d067a98047192a04f21489aca338a5d6#wechat_redirect)、[手眼标定](http://mp.weixin.qq.com/s?__biz=MzU1MjY4MTA1MQ%3D%3D&chksm=fbfc3d5acc8bb44c184084dcf447a5981d297815d62bef699129338d99a0472c622f96ee71d8&idx=2&mid=2247554670&scene=21&sn=cf3323178d5d1960476208e6303a8479#wechat_redirect)、[相机标定](http://mp.weixin.qq.com/s?__biz=MzU1MjY4MTA1MQ%3D%3D&chksm=fbff20e2cc88a9f456b80e23d2482fb319b08e89da071b39597bc51942a6aa7b756a6749856c&idx=1&mid=2247486422&scene=21&sn=381ab793959aed0eb6f01019dea522d4#wechat_redirect)、[orb-slam3](http://mp.weixin.qq.com/s?__biz=MzU1MjY4MTA1MQ%3D%3D&chksm=fbfc786acc8bf17c3a25b605bf98fe1fbe20cda72b901d1605a84c2fdfb745697e060b001eeb&idx=3&mid=2247537502&scene=21&sn=f77947414d25d79a7d64b6766f999067#wechat_redirect)等视频课程）、\***\* 知识点汇总、入门进阶学习路线、最新 paper 分享、疑问解答**五个方面进行深耕，更有各类大厂的算法工程人员进行技术指导。与此同时，星球将联合知名企业发布 3D 视觉相关算法开发岗位以及项目对接信息，打造成集技术与就业为一体的铁杆粉丝聚集区，近 2000 星球成员为创造更好的 AI 世界共同进步，知识星球入口：

* * *

学习 3D 视觉核心技术，扫描查看介绍，3 天内无条件退款

![](https://img-blog.csdnimg.cn/img_convert/bc6c98207ac7ac9d4ae0aeaca80948f3.png)

 圈里有高质量教程资料、可答疑解惑、助你高效解决问题

**觉得有用，麻烦给个赞和在看~\*\***![](https://img-blog.csdnimg.cn/img_convert/e24fa57ec35b05a1da4e19589204573b.gif)\*\*

* * *

 [https://yongqi.blog.csdn.net/article/details/120030497?spm=1001.2101.3001.6650.12&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-12-120030497-blog-124120612.topblog&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-12-120030497-blog-124120612.topblog&utm_relevant_index=13](https://yongqi.blog.csdn.net/article/details/120030497?spm=1001.2101.3001.6650.12&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-12-120030497-blog-124120612.topblog&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-12-120030497-blog-124120612.topblog&utm_relevant_index=13)
